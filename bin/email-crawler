#!/usr/bin/env ruby

require 'optparse'
require 'ostruct'

require_relative "../lib/email_crawler"

class OptionsParser
  def self.parse(args)
    options = OpenStruct.new
    options.google_website = "google.com.br"
    options.max_results = ::EmailCrawler::Scraper::MAX_RESULTS
    options.max_links = ::EmailCrawler::PageLinks::MAX_LINKS
    options.max_concurrency = ::EmailCrawler::Runner::MAX_CONCURRENCY
    options.blacklisted_domains = []

    opt_parser = OptionParser.new do |opts|
      opts.banner = "Usage: email-crawler [options]"
      opts.separator ""

      opts.on("-q", '--query "SEARCH TERM/EXPRESSION"',
              "The term/expression you want to search for") do |q|
        options.q = q
      end

      opts.on("-g", "--google-website google.com.au",
              "An alternative Google website",
              "  (defaults to Google Brazil)") do |google_website|
        options.google_website = google_website
      end

      opts.on("-r", "--max-results 250",
              "Max # of search result URLs to collect before crawling each one for email addresses",
              "  (defaults to 100)") do |max_results|
        options.max_results = max_results.to_i
      end

      opts.on("-l", "--max-links 250",
              "Max # of internal links to visit searching for emails",
              "  (per search result, defaults to 100)") do |max_links|
        options.max_links = max_links.to_i
      end

      opts.on("-c", "--concurrency 25",
              "Max # of threads to use to look for links and email addresses",
              "  (defaults to 10)") do |max_concurrency|
        options.max_concurrency = max_concurrency.to_i
      end

      opts.on("-b", "--blacklist DOMAIN",
              "Blacklist URLs under this domain from Google's search results") do |domain|
        options.blacklisted_domains << domain
      end
    end

    opt_parser.parse!(args)
    options
  end
end

options = OptionsParser.parse(ARGV)
if options.q.empty?
  print "The -q switch is mandatory\n"
  exit(1)
else
  runner = EmailCrawler::Runner.new(options.google_website) do |runner|
    runner.max_results = options.max_results
    runner.max_links = options.max_links
    runner.max_concurrency = options.max_concurrency
    runner.blacklisted_domains = options.blacklisted_domains
  end
  csv = runner.run(options.q)
  $stdout << "#{csv}\n"
end
